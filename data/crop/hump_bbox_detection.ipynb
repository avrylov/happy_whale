{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbucks2309\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/misha/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wandb_key = 'cf1380c2be4499f36827184321c87d7da7942cc7'\n",
    "wandb.login(key=api_wandb_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0  # which fold to train\n",
    "DIM = 640\n",
    "MODEL = \"yolov5x\"\n",
    "BATCH = 16\n",
    "EPOCHS = 15\n",
    "OPTMIZER = \"SGD\"\n",
    "\n",
    "PROJECT = \"hump_bbox\"  # w&b in yolov5\n",
    "NAME = f\"{MODEL}-dim{DIM}-fold{FOLD}\"  # w&b for yolov5\n",
    "\n",
    "REBEL_PATH = '/home/misha/geoframework/'\n",
    "ROOT_DIR = os.path.join(REBEL_PATH, 'models/rnd/happy_whale/data/crop')\n",
    "PROJECT_PATH = '/media/storage3/data3T/happy_whale/' + PROJECT\n",
    "\n",
    "IMAGE_DIR = os.path.join(PROJECT_PATH, 'data1', \"images\")  # directory to save images\n",
    "LABEL_DIR = os.path.join(PROJECT_PATH, 'data1', \"labels\")  # directory to save labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p {IMAGE_DIR}\n",
    "# !mkdir -p {LABEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>w_e15442c</td>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id      image_id  \\\n",
       "0  00022e1a.jpg  w_e15442c  00022e1a.jpg   \n",
       "1  000466c4.jpg  w_1287fbc  000466c4.jpg   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "\n",
       "                                          label_path  \n",
       "0  /media/storage3/data3T/happy_whale/hump_bbox/d...  \n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{PROJECT_PATH}/train.csv\")\n",
    "\n",
    "# Train Data\n",
    "\n",
    "df[\"image_id\"] = df[\"Image\"]\n",
    "df[\"image_path\"] = f\"{IMAGE_DIR}/\" + df.image_id\n",
    "df[\"label_path\"] = f\"{LABEL_DIR}/\" + df.image_id.str.replace(\"jpg\", \"txt\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbox.utils import coco2yolo, coco2voc, voc2yolo, yolo2voc\n",
    "from bbox.utils import draw_bboxes, load_image\n",
    "from bbox.utils import clip_bbox, str2annot, annot2str\n",
    "\n",
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_imgsize(row):\n",
    "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "    return row\n",
    "\n",
    "np.random.seed(32)\n",
    "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
    "          for idx in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point2bbox(points):\n",
    "    points = np.array(points)\n",
    "    points = points.astype('int') # str -> int\n",
    "    points = points.reshape(-1, 2) # shape: (None, ) -> shape: (None, 2) => (x, y) format\n",
    "    xmin, ymin, xmax, ymax = points[:, 0].min(), points[:, 1].min(), points[:, 0].max(), points[:, 1].max()\n",
    "    return [[xmin, ymin, xmax, ymax]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('cropping.txt','rt').read()\n",
    "id2point = {x.split(',')[0]:x.split(',')[1:] for x in f.split('\\n')}\n",
    "df['point'] = df['image_id'].map(id2point)\n",
    "df = df[~df.point.isna()]\n",
    "df['bbox'] = df.point.map(point2bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image-Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6224678e324e708431e66793f01988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>point</th>\n",
       "      <th>bbox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>[233, 308, 243, 301, 508, 307, 578, 391, 561, ...</td>\n",
       "      <td>[[233, 301, 578, 434]]</td>\n",
       "      <td>1050</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>[1, 63, 80, 8, 1010, 20, 1040, 28, 473, 365, 3...</td>\n",
       "      <td>[[1, 8, 1040, 366]]</td>\n",
       "      <td>1050</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id      image_id  \\\n",
       "1  000466c4.jpg  w_1287fbc  000466c4.jpg   \n",
       "2  00087b01.jpg  w_da2efe0  00087b01.jpg   \n",
       "\n",
       "                                          image_path  \\\n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "2  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "\n",
       "                                          label_path  \\\n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "2  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "\n",
       "                                               point                    bbox  \\\n",
       "1  [233, 308, 243, 301, 508, 307, 578, 391, 561, ...  [[233, 301, 578, 434]]   \n",
       "2  [1, 63, 80, 8, 1010, 20, 1040, 28, 473, 365, 3...     [[1, 8, 1040, 366]]   \n",
       "\n",
       "   width  height  \n",
       "1   1050     700  \n",
       "2   1050     368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.progress_apply(get_imgsize, axis=1)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels\n",
    "1. We need to export our labels to YOLO format, with one *.txt file per image (if no objects in image, no *.txt file is required).\n",
    "The *.txt file specifications are:\n",
    "\n",
    "    - One row per object\n",
    "\n",
    "    - Each row is class [x_center, y_center, width, height] format.\n",
    "\n",
    "    - Box coordinates must be in normalized xywh format (from 0 - 1).\n",
    "        - If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
    "\n",
    "    - Class numbers are zero-indexed (start from 0).\n",
    "\n",
    "    - Dataset bbox format is VOC-PASCAL hence [x_min, y_min, x_max, y_max].\n",
    "So, we need to convert form VOC-PASCAL to YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4211a8c32e4c1d8f88f43093b47042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "all_bboxes = []\n",
    "bboxes_info = []\n",
    "for row_idx in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[row_idx]\n",
    "    image_height = row.height\n",
    "    image_width = row.width\n",
    "    bboxes_voc = np.array(row.bbox).astype(np.float32).copy()\n",
    "    num_bbox = len(bboxes_voc)\n",
    "    names = [\"whale\"] * num_bbox\n",
    "    labels = np.array([0] * num_bbox)[..., None].astype(str)\n",
    "    ## Create Annotation(YOLO)\n",
    "    with open(row.label_path, \"w\") as f:\n",
    "        if num_bbox < 1:\n",
    "            annot = \"\"\n",
    "            f.write(annot)\n",
    "            cnt += 1\n",
    "            continue\n",
    "        #         bboxes_voc  = coco2voc(bboxes_coco, image_height, image_width)\n",
    "        bboxes_voc = clip_bbox(bboxes_voc, image_height, image_width)\n",
    "        bboxes_yolo = voc2yolo(bboxes_voc, image_height, image_width).astype(str)\n",
    "        all_bboxes.extend(bboxes_yolo.astype(float))\n",
    "        bboxes_info.extend([[row.image_id]] * len(bboxes_yolo))\n",
    "        annots = np.concatenate([labels, bboxes_yolo], axis=1)\n",
    "        string = annot2str(annots)\n",
    "        f.write(string)\n",
    "print(\"Missing:\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49523807, 0.49496222, 0.9866666 , 0.929471  ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0.49523807', '0.49496222', '0.9866666', '0.929471']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>point</th>\n",
       "      <th>bbox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>[233, 308, 243, 301, 508, 307, 578, 391, 561, ...</td>\n",
       "      <td>[[233, 301, 578, 434]]</td>\n",
       "      <td>1050</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>/media/storage3/data3T/happy_whale/hump_bbox/d...</td>\n",
       "      <td>[1, 63, 80, 8, 1010, 20, 1040, 28, 473, 365, 3...</td>\n",
       "      <td>[[1, 8, 1040, 366]]</td>\n",
       "      <td>1050</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id      image_id  \\\n",
       "1  000466c4.jpg  w_1287fbc  000466c4.jpg   \n",
       "2  00087b01.jpg  w_da2efe0  00087b01.jpg   \n",
       "\n",
       "                                          image_path  \\\n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "2  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "\n",
       "                                          label_path  \\\n",
       "1  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "2  /media/storage3/data3T/happy_whale/hump_bbox/d...   \n",
       "\n",
       "                                               point                    bbox  \\\n",
       "1  [233, 308, 243, 301, 508, 307, 578, 391, 561, ...  [[233, 301, 578, 434]]   \n",
       "2  [1, 63, 80, 8, 1010, 20, 1040, 28, 473, 365, 3...     [[1, 8, 1040, 366]]   \n",
       "\n",
       "   width  height  \n",
       "1   1050     700  \n",
       "2   1050     368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folds\n",
    "Number of samples aren't same in each fold which can create large variance in Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "df.fold.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(100) # takes samples with bbox\n",
    "y = 2\n",
    "x = 5\n",
    "plt.figure(figsize=(4 * x, 4 * y))\n",
    "for idx in range(x*y):\n",
    "    row = df2.iloc[idx]\n",
    "    img           = load_image(row.image_path)\n",
    "    img           = cv2.resize(img, (512, 512))\n",
    "    image_height  = row.height\n",
    "    image_width   = row.width\n",
    "    with open(row.label_path) as f:\n",
    "        annot = str2annot(f.read())\n",
    "    bboxes_yolo = annot[...,1:]\n",
    "    labels      = annot[..., 0].astype(int).tolist()\n",
    "    names         = ['whale']*len(bboxes_yolo)\n",
    "    plt.subplot(y, x, idx+1)\n",
    "    plt.imshow(draw_bboxes(img = img,\n",
    "                           bboxes = bboxes_yolo, \n",
    "                           classes = names,\n",
    "                           class_ids = labels,\n",
    "                           class_name = True, \n",
    "                           colors = colors, \n",
    "                           bbox_format = 'yolo',\n",
    "                           line_thickness = 2))\n",
    "    plt.axis('OFF')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'].values[0].replace('x/data/train', 'x/data1/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'] = df.apply(lambda x: x['image_path'].replace('x/data/train', 'x/data1/images'), axis=1)\n",
    "\n",
    "df['label_path'] = df.apply(lambda x: x['image_path'].replace('x/data', 'x/data1'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "train_df = df.query(\"fold!=@FOLD\")\n",
    "valid_df = df.query(\"fold==@FOLD\")\n",
    "train_files += list(train_df.image_path.unique())\n",
    "val_files += list(valid_df.image_path.unique())\n",
    "len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "The dataset config file requires\n",
    "\n",
    "1. The dataset root directory path and relative paths to train / val / test image directories (or *.txt files with image paths)\n",
    "2. The number of classes nc and\n",
    "3. A list of class names:['cots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.join(PROJECT_PATH, 'working')\n",
    "\n",
    "with open(os.path.join(cwd , 'train.txt'), 'w') as f:\n",
    "    for path in train_df.image_path.tolist():\n",
    "        f.write(path+'\\n')\n",
    "            \n",
    "with open(os.path.join(cwd , 'val.txt'), 'w') as f:\n",
    "    for path in valid_df.image_path.tolist():\n",
    "        f.write(path+'\\n')\n",
    "\n",
    "data = dict(\n",
    "    path  = cwd,\n",
    "    train =  os.path.join( cwd , 'train.txt') ,\n",
    "    val   =  os.path.join( cwd , 'val.txt' ),\n",
    "    nc    = 1,\n",
    "    names = ['whale'],\n",
    "    )\n",
    "\n",
    "with open(os.path.join( cwd , 'happywhale.yaml'), 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n",
    "f = open(os.path.join( cwd , 'happywhale.yaml'), 'r')\n",
    "print('\\nyaml:')\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /media/storage3/data3T/happy_whale/hump_bbox/working/hyp.yaml\n",
    "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 0.05  # box loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.20  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "# anchors: 3  # anchors per output layer (0 to ignore)\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 30.0  # image rotation (+/- deg)\n",
    "translate: 0.10  # image translation (+/- fraction)\n",
    "scale: 0.80  # image scale (+/- gain)\n",
    "shear: 10.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.5  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 0.75  # image mosaic (probability)\n",
    "mixup: 0.0 # image mixup (probability)\n",
    "copy_paste: 0.0  # segment copy-paste (probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv5¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /media/storage3/data3T/happy_whale/hump_bbox/working\n",
    "# !git clone https://github.com/ultralytics/yolov5 # clone\n",
    "\n",
    "%cd yolov5\n",
    "# %pip install -qr requirements.txt  # install\n",
    "\n",
    "from yolov5 import utils\n",
    "_ = utils.notebook_init()  # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run script in tmux session\n",
    "!python3 train.py --img {DIM}\\\n",
    "--batch {BATCH}\\\n",
    "--epochs {EPOCHS}\\\n",
    "--optimizer {OPTMIZER}\\\n",
    "--data /media/storage3/data3T/happy_whale/hump_bbox/happywhale.yaml\\\n",
    "--hyp /media/storage3/data3T/happy_whale/hump_bbox/hyp.yaml\\\n",
    "--weights {MODEL}.pt\\\n",
    "--project {PROJECT} --name {NAME}\\\n",
    "--exist-ok\n",
    "# python3 train.py --img 640 --batch 16 --epochs 15 --optimizer 'SGD' --data /media/storage3/data3T/happy_whale/hump_bbox/working/happywhale.yaml --hyp /media/storage3/data3T/happy_whale/hump_bbox/working/hyp.yaml --weights \"yolov5x\".pt --project \"happywhale-det-public\" --name 'yolov5x-dim640-fold0' --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(cwd, 'yolov5', 'happywhale-det-public/yolov5x-dim640-fold0')\n",
    "!ls {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {OUTPUT_DIR}/weights/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whale and Dolphin Data 🐋🐬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    base_path = '/media/storage3/data3T/happy_whale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = CFG.base_path + '/output/train'\n",
    "test_output = CFG.base_path + '/output/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(CFG.base_path + \"/train.csv\")\n",
    "df2[\"image_id\"] = df2[\"image\"]\n",
    "df2[\"label_path\"] = train_output + \"/labels/\" + df2[\"image_id\"].str.replace('jpg','txt')\n",
    "\n",
    "test_df2 = pd.DataFrame(\n",
    "    data={\n",
    "        'image': os.listdir(CFG.base_path + '/test_images')\n",
    "    }\n",
    ")\n",
    "test_df2[\"image_id\"] = test_df2[\"image\"]\n",
    "test_df2[\"label_path\"] = test_output + \"/labels/\" + test_df2[\"image_id\"].str.replace('jpg','txt')\n",
    "\n",
    "print(\"Train Images: {:,} | Test Images: {:,}\".format(len(df2), len(test_df2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 detect.py --img 640 --source /media/storage3/data3T/happy_whale/train_images --weights /media/storage3/data3T/happy_whale/hump_bbox/working/yolov5/happywhale-det-public/yolov5x-dim640-fold0/weights/best.pt --project /media/storage3/data3T/happy_whale/output --name train --conf 0.01 --iou 0.4 --max-det 1 --save-txt --save-conf --nosave --half --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"image_path\"] = f\"{CFG.base_path}/train_images/\" + df2.image_id\n",
    "df2 = df2.progress_apply(get_imgsize, axis=1)\n",
    "display(df2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(df):\n",
    "    df2_sample = df.sample(100) # takes samples with bbox\n",
    "    y = 2\n",
    "    x = 5\n",
    "    plt.figure(figsize=(4 * x, 4 * y))\n",
    "    for idx in range(x*y):\n",
    "        row = df2_sample.iloc[idx]\n",
    "        img           = load_image(row.image_path)\n",
    "        img           = cv2.resize(img, (512, 512))\n",
    "        image_height  = row.height\n",
    "        image_width   = row.width\n",
    "        with open(row.label_path) as f:\n",
    "            txt = f.read()\n",
    "            txt = ' '.join(txt.split(' ')[:-1])\n",
    "            annot = str2annot(txt)\n",
    "        bboxes_yolo = annot[...,1:]\n",
    "        labels      = annot[..., 0].astype(int).tolist()\n",
    "        names         = ['whale']*len(bboxes_yolo)\n",
    "        plt.subplot(y, x, idx+1)\n",
    "        plt.imshow(draw_bboxes(img = img,\n",
    "                               bboxes = bboxes_yolo, \n",
    "                               classes = names,\n",
    "                               class_ids = labels,\n",
    "                               class_name = True, \n",
    "                               colors = colors, \n",
    "                               bbox_format = 'yolo',\n",
    "                               line_thickness = 2))\n",
    "        plt.axis('OFF')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 detect.py --img 640 --source /media/storage3/data3T/happy_whale/test_images --weights /media/storage3/data3T/happy_whale/hump_bbox/working/yolov5/happywhale-det-public/yolov5x-dim640-fold0/weights/best.pt --project /media/storage3/data3T/happy_whale/output --name test --conf 0.01 --iou 0.4 --max-det 1 --save-txt --save-conf --nosave --half --exist-ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2[\"image_path\"] = f\"{CFG.base_path}/test_images/\" + test_df2.image_id\n",
    "test_df2 = test_df2.progress_apply(get_imgsize, axis=1)\n",
    "display(test_df2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "co2",
   "language": "python",
   "name": "co2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}